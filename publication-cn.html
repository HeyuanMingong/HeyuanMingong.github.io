<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="favicon.ico" />
<link rel="bookmark" href="favicon.ico" type="image/x-icon"　/>
<title>王志</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">目录</div>
<div class="menu-item"><a href="index-cn.html">主页</a></div>
<div class="menu-item"><a href="publication-cn.html" class="current">论文</a></div>
<div class="menu-item"><a href="people-cn.html">成员</a></div>
<div class="menu-item"><a href="teaching-cn.html">教学</a></div>
<div class="menu-item"><a href="cv_zhiwang_cn_website.pdf">简历</a></div>
<div class="menu-item"><a href="index.html">English</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>主要论文</h1>
</div>


<h3>预印本</h3>
<ul>
 <li><p>Zichuan Liu, Yuanyang Zhu, <b>Zhi Wang</b>, Yang Gao, and Chunlin Chen, "<a href="https://arxiv.org/abs/2209.07225">MIXRTs: Toward interpretable multi-agent reinforcement learning via mixing recurrent soft decision trees</a>," <i>arXiv preprint arXiv:2209.07225</i>, 2022. 
 </p> </li>
</ul>

<h3>2023</h3>
<ul>
 <li><p>王君逸, <b>王志*</b>, 李华雄, 陈春林. <a href="http://www.aas.net.cn/cn/article/doi/10.16383/j.aas.c220103?viewType=HTML">基于自适应噪声的最大熵进化强化学习方法</a>. 自动化学报, 2023, 49(1): 54−66. [<a href="paper/AERL_ME.pdf">pdf</a>] 
 </p> </li>
</ul>

<h3>2022</h3>
<ul>
 <li><p>Donghan Xie, <b>Zhi Wang*</b>, Chunlin Chen, and Daoyi Dong, "<a href="https://ieeexplore.ieee.org/document/10003136/metrics">Depthwise convolution for multi-agent communication with enhanced mean-field approximation</a>," <i>IEEE Transactions on Neural Networks and Learning Systems</i>, 2022, DOI: 10.1109/TNNLS.2022.3230701. [<a href="paper/DCCP.pdf">pdf</a>]
 </p> </li>

 <li><p><b>Zhi Wang</b>, Chunlin Chen, and Daoyi Dong, "<a href="https://ieeexplore.ieee.org/abstract/document/9353402/">Lifelong incremental reinforcement learning with online Bayesian inference</a>," <i>IEEE Transactions on Neural Networks and Learning Systems</i>, 2022, 33(8): 4003-4016. [<a href="paper/LLIRL.pdf">pdf</a>] [<a href="https://github.com/HeyuanMingong/llirl">code</a>]
 </p> </li>

<li><p><b>Zhi Wang</b>, Chunlin Chen, and Daoyi Dong, "<a href="https://ieeexplore.ieee.org/document/9777250">A Dirichlet process mixture of robust task models for scalable lifelong reinforcement learning</a>," <i>IEEE Transactions on Cybernetics</i>, 2022, DOI: 10.1109/TCYB.2022.3170485. [<a href="paper/SLLRL.pdf">pdf</a>] [<a href="https://github.com/HeyuanMingong/sllrl">code</a>]
 </p> </li>

 <li><p><b>Zhi Wang</b>, Chunlin Chen, and Daoyi Dong, "<a href="https://ieeexplore.ieee.org/abstract/document/9744521">Instance weighted incremental evolution strategies for reinforcement learning in dynamic environments</a>," <i>IEEE Transactions on Neural Networks and Learning Systems</i>, 2022, DOI: 10.1109/TNNLS.2022.3160173. [<a href="paper/IWIES.pdf">pdf</a>] [<a href="https://github.com/HeyuanMingong/iwies">code</a>]
 </p> </li>

  <li><p>Yuanyang Zhu, <b>Zhi Wang*</b>, Chunlin Chen, and Daoyi Dong, "<a href="https://ieeexplore.ieee.org/document/9403986">Instance weighted incremental evolution strategies for reinforcement learning in dynamic environments</a>," <i>IEEE-ASME Transactions on Mechatronics</i>, 2022, 27(2): 846-857. [<a href="paper/RuRL.pdf">pdf</a>] [<a href="paper/RuRL_supp.pdf">supp</a>]
 </p> </li>
</ul>


<h3>2021</h3>
<ul>
 <li><p><b>Zhi Wang</b> and Han-Xiong Li, "<a href="https://ieeexplore.ieee.org/document/8730299">Dissimilarity analysis based multimode modeling for complex distributed parameter systems</a>," <i>IEEE Transactions on Systems, Man, and Cybernetics: Systems</i>, 2021, 51(5): 2789-2797. [<a href="paper/DA_MMM.pdf">pdf</a>]
 </p> </li>
</ul>


<h3>2020</h3>
<ul>
 <li><p><b>Zhi Wang</b>, Han-Xiong Li, and Chunlin Chen, "<a href="https://ieeexplore.ieee.org/document/8786875">Incremental reinforcement learning in continuous spaces via policy relaxation and importance weighting</a>," <i>IEEE Transactions on Neural Networks and Learning Systems</i>, 2020, 31(6): 1870-1883. [<a href="paper/IRL_CS.pdf">pdf</a>] [<a href="https://github.com/HeyuanMingong/irl_cs">code</a>]
 </p> </li>

<li><p><b>Zhi Wang</b>, Han-Xiong Li, and Chunlin Chen, "<a href="https://ieeexplore.ieee.org/document/8668561">Reinforcement learning based optimal sensor placement for spatiotemporal modeling</a>," <i>IEEE Transactions on Cybernetics</i>, 2020, 50(6): 2861-2871. [<a href="paper/RL_OSP.pdf">pdf</a>]
 </p> </li>
</ul>


<h3>2019</h3>
<ul>
 <li><p><b>Zhi Wang</b>, Chunlin Chen, Han-Xiong Li, Daoyi Dong, and Tzyh-Jong Tarn, "<a href="https://ieeexplore.ieee.org/document/8642342">Incremental reinforcement learning with prioritized sweeping for dynamic environments</a>," <i>IEEE-ASME Transactions on Mechatronics</i>, 2019, 24(2): 621-632. [<a href="paper/IRL.pdf">pdf</a>] [<a href="https://github.com/HeyuanMingong/irl">code</a>]
 </p> </li>

<li><p><b>Zhi Wang</b> and Han-Xiong Li, "<a href="https://ieeexplore.ieee.org/document/8319440">Incremental learning for online modeling of distributed parameter systems</a>," <i>IEEE Transactions on Systems, Man, and Cybernetics: Systems</i>, 2019, 49(12): 2612-2622. [<a href="paper/IKL.pdf">pdf</a>]
 </p> </li>

 <li><p><b>Zhi Wang</b>, Wei Bi, Yan Wang, and Xiaojiang Liu, "<a href="https://aaai.org/ojs/index.php/AAAI/article/view/4709">Better fine-tuning via instance weighting for text classification</a>," <i>Proceedings of AAAI Conference on Artificial Intelligence (AAAI)</i>, 2019, 7241-7248. [<a href="paper/IW_Fit.pdf">pdf</a>] [<a href="paper/IW_Fit_supp.pdf">supp</a>]
 </p> </li>
</ul>






<p><b>备注</b>: *表示通讯作者.</p>


</td>
</tr>
</table>
</body>
</html>
























