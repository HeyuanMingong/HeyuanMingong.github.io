<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<!--<link rel="shortcut icon" href="nju_logo_circle.png" />
<link rel="bookmark" href="nju_logo_circle.png" type="image/x-icon"　/>-->
<link rel="icon" type="image/png" href="nju_logo_circle.png">
<title>Zhi Wang</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">目录</div>
<div class="menu-item"><a href="index-cn.html">主页</a></div>
<div class="menu-item"><a href="publication-cn.html">论文</a></div>
<div class="menu-item"><a href="people-cn.html" class="current">成员</a></div>
<div class="menu-item"><a href="teaching-cn.html">教学</a></div>
<div class="menu-item"><a href="cv_zhiwang_cn_website.pdf">简历</a></div>
<div class="menu-item"><a href="index.html">English</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>协助指导学生</h1>
</div>


<h3>朱远洋, 硕士, 2018-2021</h3>
<ul>
  <li><p><b>Yuanyang Zhu</b>, Zhi Wang*, Chunlin Chen, and Daoyi Dong, "<a href="https://ieeexplore.ieee.org/document/9403986">Rule-based reinforcement learning for efficient robot navigation with space reduction</a>," <i>IEEE-ASME Transactions on Mechatronics</i>, 2022, 27(2): 846-857. [<a href="paper/RuRL.pdf">pdf</a>] [<a href="paper/RuRL_supp.pdf">supp</a>]
 </p> </li>

  <li><p>Zichuan Liu, <b>Yuanyang Zhu</b>, Zhi Wang, Yang Gao, and Chunlin Chen, "<a href="https://arxiv.org/abs/2209.07225">MIXRTs: Toward interpretable multi-agent reinforcement learning via mixing recurrent soft decision trees</a>," <i>arXiv preprint arXiv:2209.07225</i>, 2022. 
 </p> </li>
</ul>

<h3>谢东瀚, 硕士, 2018-2021</h3>
<ul>
 <li><p><b>Donghan Xie</b>, Zhi Wang*, Chunlin Chen, and Daoyi Dong, "<a href="https://ieeexplore.ieee.org/document/10003136/metrics">Depthwise convolution for multi-agent communication with enhanced mean-field approximation</a>," <i>IEEE Transactions on Neural Networks and Learning Systems</i>, 2022, DOI: 10.1109/TNNLS.2022.3230701. [<a href="paper/DCCP.pdf">pdf</a>]
 </p> </li>

  <li><p><b>Donghan Xie</b>, Zhi Wang, Chunlin Chen, and Daoyi Dong, "IEDQN: Information exchange DQN with a centralized coordinator for traffic signal control," <i>IEEE International Joint Conference on Neural Networks</i>, 2020.
 </p> </li>
</ul>


<h3>刘金梅, 硕士, 2020-2023</h3>
<ul>
 <li><p><b>Jinmei Liu</b>, Zhi Wang*, Chunlin Chen, and Daoyi Dong, "Efficient Bayesian policy reuse with a scalable observation model in deep reinforcement learning," under review at <i>IEEE Transactions on Neural Networks and Learning Systems</i>, 2nd round.
 </p> </li>

  <li><p><b>Jinmei Liu</b>, Zhi Wang, and Chunlin Chen, "Fast probabilistic policy reuse via reward function fitting," <i>IEEE International Joint Conference on Neural Networks</i>, 2022.
 </p> </li>
</ul>

<h3>覃友, 硕士, 2020-2023</h3>
<ul>
  <li><p><b>You Qin</b>, Zhi Wang, and Chunlin Chen, "HRL2E: Hierarchical reinforcement learning with low-level ensemble," <i>IEEE International Joint Conference on Neural Networks</i>, 2022.
 </p> </li>
</ul>


<h3>丁泓宇, 硕士, 2021-2024</h3>
<ul>
 <li><p><b>Hongyu Ding</b>, Yuanze Tang, Qing Wu, Bo Wang, Chunlin Chen, Zhi Wang*, "Magnetic field-base reward shaping for goal-conditioned reinforcement learning," under review at <i>IEEE-CAA Journal of Automatica Sinica</i>, 3rd round.
 </p> </li>
</ul>


<h3>王君逸, 硕士, 2021-2024</h3>
<ul>
 <li><p><b>王君逸</b>, 王志*, 李华雄, 陈春林. <a href="http://www.aas.net.cn/cn/article/doi/10.16383/j.aas.c220103?viewType=HTML">基于自适应噪声的最大熵进化强化学习方法</a>. 自动化学报, 2023, 49(1): 54−66. [<a href="paper/AERL_ME.pdf">pdf</a>] 
 </p> </li>
</ul>

<h3>胡紫灿, 硕士, 2022-2025</h3>

<h3>信旺, 硕士, 2022-2025</h3>




</td>
</tr>
</table>
</body>
</html>
























