<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<!--<link rel="shortcut icon" href="nju_logo_circle.png" />
<link rel="bookmark" href="nju_logo_circle.png" type="image/x-icon"　/>-->
<link rel="icon" type="image/png" href="nju_logo_circle.png">
<title>Zhi Wang</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
  <div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="publication.html">Publications</a></div>
<div class="menu-item"><a href="people.html" class="current">People</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="cv_zhiwang_website.pdf">CV</a></div>
<div class="menu-item"><a href="index-cn.html">中文</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Co-Supervised Students</h1>
</div>


<h3>Yuanyang Zhu, Master, 2018-2021</h3>
<ul>
  <li><p><b>Yuanyang Zhu</b>, Zhi Wang*, Chunlin Chen, and Daoyi Dong, "<a href="https://ieeexplore.ieee.org/document/9403986">Rule-based reinforcement learning for efficient robot navigation with space reduction</a>," <i>IEEE-ASME Transactions on Mechatronics</i>, 2022, 27(2): 846-857. [<a href="paper/RuRL.pdf">pdf</a>] [<a href="paper/RuRL_supp.pdf">supp</a>]
 </p> </li>

  <li><p>Zichuan Liu, <b>Yuanyang Zhu</b>, Zhi Wang, Yang Gao, and Chunlin Chen, "<a href="https://arxiv.org/abs/2209.07225">MIXRTs: Toward interpretable multi-agent reinforcement learning via mixing recurrent soft decision trees</a>," <i>arXiv preprint arXiv:2209.07225</i>, 2022. 
 </p> </li>
</ul>

<h3>Donghan Xie, Master, 2018-2021</h3>
<ul>
 <li><p><b>Donghan Xie</b>, Zhi Wang*, Chunlin Chen, and Daoyi Dong, "<a href="https://ieeexplore.ieee.org/document/10003136/metrics">Depthwise convolution for multi-agent communication with enhanced mean-field approximation</a>," <i>IEEE Transactions on Neural Networks and Learning Systems</i>, 2022, DOI: 10.1109/TNNLS.2022.3230701. [<a href="paper/DCCP.pdf">pdf</a>]
 </p> </li>

  <li><p><b>Donghan Xie</b>, Zhi Wang, Chunlin Chen, and Daoyi Dong, "IEDQN: Information exchange DQN with a centralized coordinator for traffic signal control," <i>IEEE International Joint Conference on Neural Networks</i>, 2020.
 </p> </li>
</ul>


<h3>Jinmei Liu, Master, 2020-2023</h3>
<ul>

  <li><p><b>Jinmei Liu</b>, Zhi Wang, and Chunlin Chen, "Fast probabilistic policy reuse via reward function fitting," <i>IEEE International Joint Conference on Neural Networks</i>, 2022.
 </p> </li>
</ul>

<h3>You Qin, Master, 2020-2023</h3>
<ul>
  <li><p><b>You Qin</b>, Zhi Wang, and Chunlin Chen, "HRL2E: Hierarchical reinforcement learning with low-level ensemble," <i>IEEE International Joint Conference on Neural Networks</i>, 2022.
 </p> </li>
</ul>


<h3>Hongyu Ding, Master, 2021-2024</h3>
<ul>
<li><p><b>Hongyu Ding</b>, Yuanze Tang, Qing Wu, Bo Wang, Chunlin Chen, Zhi Wang*, "Magnetic field-base reward shaping for goal-conditioned reinforcement learning," <i>IEEE-CAA Journal of Automatica Sinica</i>, 2023, DOI: 10.1109/JAS.2023.123477. [<a href="https://github.com/Darkness-hy/mfrs">code</a>] [<a href="https://hongyuding.wixsite.com/mfrs">video</a>]
</p></li>
</ul>


<h3>Junyi Wang, Master, 2021-2024</h3>
<ul>
<li><p><b>Junyi Wang</b>, Zhi Wang*, Huaxiong Li, and Chunlin Chen, "<a href="http://www.aas.net.cn/cn/article/doi/10.16383/j.aas.c220103?viewType=HTML">Adaptive noise-based evolutionary reinforcement learning with maximum entropy</a>," <i>Acta Automatica Sinica</i>, 2023, 49(1): 54−66. [<a href="paper/AERL_ME.pdf">pdf</a>] 
 </p> </li>
</ul>

<h3>Zican Hu, Master, 2022-2025</h3>

<h3>Wang Xin, Master, 2022-2025</h3>




</td>
</tr>
</table>
</body>
</html>
























